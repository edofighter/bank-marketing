{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4f7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de train/test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebfdfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en Class: [1 2]\n",
      "(36168, 15) (9043, 15)\n",
      "Proporción train: 0.117\n",
      "Proporción test: 0.117\n",
      "(36168, 15) (9043, 15)\n",
      "Proporción train: 0.117\n",
      "Proporción test: 0.117\n"
     ]
    }
   ],
   "source": [
    "#Preparamos X e y, revisando valores únicos y limpiando NaN en y\n",
    "\n",
    "df = pd.read_csv('../data/raw/bank_marketing.csv') \n",
    "print('Valores únicos en Class:', df['Class'].unique())\n",
    "\n",
    "# Normalizar valores a string y minúsculas para evitar problemas de formato\n",
    "class_values = set(str(val).strip().lower() for val in df['Class'].unique())\n",
    "\n",
    "# Mapear la variable objetivo según los valores únicos detectados\n",
    "if class_values == {'1', '2'}:\n",
    "    y = df['Class'].astype(int).map({1: 0, 2: 1})\n",
    "elif class_values == {'no', 'yes'}:\n",
    "    y = df['Class'].map({'no': 0, 'yes': 1})\n",
    "elif class_values == {'0', '1'}:\n",
    "    y = df['Class'].astype(int)\n",
    "else:\n",
    "    print('Advertencia: valores inesperados en Class, no se realiza mapeo binario.')\n",
    "    y = df['Class']\n",
    "\n",
    "# Eliminar columnas de fuga y target de X\n",
    "X = df.drop(columns=['Class', 'V12']) if 'V12' in df.columns else df.drop(columns=['Class'])\n",
    "\n",
    "# Limpiar NaN en y y ajustar X\n",
    "if y.isnull().any():\n",
    "    print(f\"Advertencia: Se encontraron {y.isnull().sum()} valores NaN en y tras el mapeo. Se eliminarán esas filas.\")\n",
    "    X = X.loc[~y.isnull(), :].copy()\n",
    "    y = y.dropna()\n",
    "\n",
    "# Split de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(\"Proporción train:\", y_train.mean().round(3))\n",
    "print(\"Proporción test:\", y_test.mean().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ea28dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      7985\n",
      "           1       0.66      0.18      0.28      1058\n",
      "\n",
      "    accuracy                           0.89      9043\n",
      "   macro avg       0.78      0.58      0.61      9043\n",
      "weighted avg       0.87      0.89      0.87      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo baseline\n",
    "#Codificar variables categóricas\n",
    "X_train_enc = pd.get_dummies(X_train)\n",
    "X_test_enc = pd.get_dummies(X_test)\n",
    "\n",
    "# Alinear columnas de test con train\n",
    "X_test_enc = X_test_enc.reindex(columns=X_train_enc.columns, fill_value=0)\n",
    "\n",
    "# Escalar variables numéricas\n",
    "scaler = StandardScaler()\n",
    "num_cols = X_train_enc.select_dtypes(include=['float64', 'int64']).columns\n",
    "X_train_enc[num_cols] = scaler.fit_transform(X_train_enc[num_cols])\n",
    "X_test_enc[num_cols] = scaler.transform(X_test_enc[num_cols])\n",
    "\n",
    "# Entrenar el modelo con los datos codificados y escalados\n",
    "baseline = LogisticRegression(max_iter=1000)\n",
    "baseline.fit(X_train_enc, y_train)\n",
    "\n",
    "y_pred = baseline.predict(X_test_enc)\n",
    "y_prob = baseline.predict_proba(X_test_enc)[:,1]\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob).round(3))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd271396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar resultados iniciales\n",
    "df = pd.read_csv('../data/raw/bank_marketing.csv') \n",
    "\n",
    "fig_dir = Path('../reports/figures')\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "if 'Class' in df.columns:\n",
    "    sns.countplot(x='Class', data=df)\n",
    "    plt.title('Distribución de la variable objetivo')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fig_dir, 'class_distribution.png'))\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"La columna 'Class' no existe en el DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8f27377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en Class: [1 2]\n",
      "Advertencia: valores inesperados en Class, no se realiza mapeo binario.\n",
      "Variables numéricas: ['V1', 'V6', 'V10', 'V12', 'V13', 'V14', 'V15']\n",
      "Variables categóricas: ['V2', 'V3', 'V4', 'V5', 'V7', 'V8', 'V9', 'V11', 'V16']\n"
     ]
    }
   ],
   "source": [
    "#Preprocesamiento y Feature Engineering\n",
    "#cargar datos\n",
    "df = pd.read_csv('../data/raw/bank_marketing.csv')\n",
    "\n",
    "# Verificar valores únicos en la columna objetivo\n",
    "if 'Class' in df.columns:\n",
    "    print('Valores únicos en Class:', df['Class'].unique())\n",
    "else:\n",
    "    raise ValueError(\"La columna 'Class' no existe en el archivo CSV.\")\n",
    "\n",
    "# Mapear la variable objetivo a binaria si los valores son 'yes' y 'no'\n",
    "if set(df['Class'].dropna().unique()) == {'yes', 'no'}:\n",
    "    df['Class'] = df['Class'].map({'yes': 1, 'no': 0})\n",
    "else:\n",
    "    print(\"Advertencia: valores inesperados en Class, no se realiza mapeo binario.\")\n",
    "\n",
    "y = df['Class']\n",
    "\n",
    "# Eliminar filas con NaN en la variable objetivo\n",
    "if y.isnull().any():\n",
    "    print(f\"Advertencia: Se encontraron {y.isnull().sum()} valores NaN en y. Se eliminarán esas filas.\")\n",
    "    df = df.loc[~y.isnull(), :].copy()\n",
    "    y = y.dropna()\n",
    "\n",
    "# Eliminar columnas de fuga si existen\n",
    "cols_to_drop = ['Class', 'duration']\n",
    "X = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "\n",
    "#Split estratificado\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "#Identificar variables categóricas y numéricas\n",
    "num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print('Variables numéricas:', num_features)\n",
    "print('Variables categóricas:', cat_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
